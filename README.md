# Sequence-Based Filtering for Visual Route-Based Navigation

This repository provides sequence-based implementations of five Visual Place Recognition (VPR) techniques â€” <b>AMOSNet</b>, <b>HybridNet</b>, <b>CALC</b>, <b>HOG</b>, and <b>NetVLAD</b> â€” as described in the accompanying paper.

**Title:** Sequence-Based Filtering for Visual Route-Based Navigation: Analyzing the Benefits, Trade-Offs and Design Choices <br>
**Authors:** Mihnea-Alexandru Tomita, Mubariz Zaffar, Bruno Ferrarini, Michael J. Milford, Klaus D. McDonald-Maier and Shoaib Ehsan 

Published in IEEE Access, vol. 10, pp. 81974-81987, 2022 and available ðŸ“‘ [here](https://doi.org/10.1109/ACCESS.2022.3196389).

The goal of this work is to systematically investigate the effects of sequence-based filtering on top of single-frame-based VPR techniques for route-based navigation. We analyze the trade-offs between accuracy and computational cost, examine the impact of sequence length, and identify combinations of techniques that deliver high performance efficiently. 

> **Note:** The sequence-based implementations of RegionVLAD and AlexNet are also provided in this repository for completeness, although they were not evaluated in the paper.

## ðŸ“‚ Repository Structure
<pre>
â”œâ”€â”€ AMOSNet/                   # AMOSNet supporting files â€“ Add <b>AmosNet.caffemodel</b> in this folder
â”‚   â”œâ”€â”€ ReadMe.txt             # Original AMOSNet citations
â”‚   â”œâ”€â”€ amosnet_mean.npy       
â”‚   â””â”€â”€ deploy.prototxt 
â”œâ”€â”€ AlexNet/                   # AlexNet files
â”‚   â”œâ”€â”€ AlexNet_k.py           # Sequence-based AlexNet implementation
â”‚   â”œâ”€â”€ ReadMe.txt             # Original AlexNet citations  
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ alexnet/               # Network configuration folder - Add <b>alexnet.caffemodel</b> in this folder
â”‚       â””â”€â”€ deploy.prototxt  
â”œâ”€â”€ CALC/                      # CALC supporting files
â”‚   â”œâ”€â”€ ReadMe.txt             # Original CALC citations
â”‚   â”œâ”€â”€ model/                 # Add calc.caffemodel in this folder
â”‚   â”‚   â””â”€â”€ ReadMe.txt         
â”‚   â””â”€â”€ proto/                 # Contains network configuration
â”‚       â””â”€â”€ deploy.prototxt
â”œâ”€â”€ HOG/                       # HOG files
â”‚   â”œâ”€â”€ HOG_k.py               # Sequence-based HOG implementation
â”‚   â””â”€â”€ ReadMe.txt             # Original HOG citations
â”œâ”€â”€ HybridNet/                 # HybridNet supporting files â€“ Add <b>HybridNet.caffemodel</b> in this folder
â”‚   â”œâ”€â”€ hybridnet_mean.npy     # Pretrained weights
â”‚   â”œâ”€â”€ deploy.prototxt        # Network configuration
â”‚   â””â”€â”€ ReadMe.txt             # Original HybridNet citations
â”œâ”€â”€ NetVLAD/                   # NetVLAD files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ReadMe.txt             # Original NetVLAD citations
â”‚   â”œâ”€â”€ NetVLAD_k.py           # Sequence-based NetVLAD implementation
â”‚   â”œâ”€â”€ checkpoints/           # Add the <b>checkpoints</b> for the NetVLAD model to this folder
â”‚   â”‚   â””â”€â”€ ReadMe.txt         
â”‚   â””â”€â”€ netvlad_tf/            # Supporting TensorFlow modules
â”‚       â”œâ”€â”€ .gitignore
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ image_descriptor.py
â”‚       â”œâ”€â”€ layers.py
â”‚       â”œâ”€â”€ mat_to_checkpoint.py
â”‚       â”œâ”€â”€ net_from_mat.py
â”‚       â””â”€â”€ nets.py
â”œâ”€â”€ RegionVLAD/                # RegionVLAD files
â”‚   â”œâ”€â”€ RegionVLAD_k.py        # Sequence-based RegionVLAD implementation
â”‚   â”œâ”€â”€ ReadMe.txt             # Original RegionVLAD citations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ Vocabulary/            # Pre-computed vocabularies
â”‚   â”‚   â”œâ”€â”€ Vocabulary_100_200_300_Protocol2.pkl
â”‚   â”‚   â”œâ”€â”€ Vocabulary_100_200_300_Protocol3.pkl
â”‚   â”‚   â”œâ”€â”€ Vocabulary_400_Protocol2.pkl
â”‚   â”‚   â””â”€â”€ Vocabulary_400_Protocol3.pkl
â”‚   â””â”€â”€ AlexnetPlaces365/      # Supporting files for AlexNet backbone â€“ Add <b>alexnet_places365.caffemodel</b> to this folder
â”‚       â”œâ”€â”€ deploy_alexnet_places365.prototxt
â”‚       â””â”€â”€ places365CNN_mean.binaryproto  
â”œâ”€â”€ figures/ 
â”‚   â””â”€â”€ plot_figure3.py        # Script to reproduce Figure 3
â”œâ”€â”€ AMOSNet_k.py               # Sequence-based AMOSNet implementation
â”œâ”€â”€ CALC_k.py                  # Sequence-based CALC implementation
â”œâ”€â”€ HybridNet_k.py             # Sequence-based HybridNet implementation 
â”œâ”€â”€ MODEL_DOWNLOADS.md         # Markdown file containing download links and instructions for all pretrained models    
</pre>

## ðŸ“¦ Pretrained Models

[MODEL_DOWNLOADS.md](MODEL_DOWNLOADS.md) provides the web locations and instructions for downloading all pretrained models required by the VPR techniques in this repository. These files are not included due to size restrictions.

## ðŸ›  Required Libraries By Technique:
- **AMOSNet:** `caffe`, `numpy`, `cv2`, `csv`       
- **CALC:** `caffe`, `numpy`, `cv2`, `csv`, `time`     
- **HOG:** `numpy`, `cv2`, `csv`
- **HybridNet:** `caffe`, `numpy`, `cv2`, `csv`                  
- **NetVLAD:** `tensorflow`, `numpy`, `cv2`, `csv`, `time`
- **RegionVLAD:** `caffe`, `numpy`, `cv2`, `csv`, `skimage`, `pickle`, `itertools`, `time`, `os`
- **AlexNet:** `caffe`, `numpy`, `cv2`, `csv`, `os`           


## ðŸš€ Running the Sequence-Based VPR Techniques
> **Note:** For each VPR technique in this repository, the Python files are named with a `_k` suffix (e.g. `NetVLAD_k.py`). This indicates that the implementation uses sequence-based filtering, where `k` represents the number of consecutive images in each sequence. The value of `k` can be adjusted for each technique. For more details, please refer to the accompanying paper.

Before running any `.py` file, update the following variables:
- `total_Query_Images` â†’ Number of images in the **query folder**.
- `total_Ref_Images` â†’ Number of images in the **reference folder**.
- `query_directory` â†’ Path to your **query images** folder.
- `ref_directory` â†’ Path to your **reference images** folder.
- `k` â†’ Number of consecutive images in the sequence. Set `k = 1` to disable sequence-based filtering.

<pre>
total_Query_Images = 1000  # Number of images in the query folder
total_Ref_Images   = 1000  # Number of images in the reference folder

query_directory = '/path/to/query/images'
ref_directory   = '/path/to/reference/images'

k = 10  # Sequence length
</pre>

Once these variables are correctly set, you can run the corresponding `_k.py` file for your chosen technique.

## ðŸ“Š Datasets
The experiments use the following publicly available sequential VPR datasets:
- Campus Loop
- Gardens Point (day-to-day) 
- Gardens Point (day-to-night) 
- Nordland 

For more details on these datasets, including environmental conditions and experimental setup, please refer to our paper.

## ðŸ“Œ Key Findings
- Sequence-based filtering consistently improves VPR accuracy by leveraging sequences of consecutive images.
- Lightweight descriptors such as HOG or CALC can sometimes outperform deep learning methods like NetVLAD while requiring less computation.
- Deep learning-based methods such as AMOSNet, HybridNet and NetVLAD are more robust under severe environmental and viewpoint changes but require more computational resources.
- Sequence-based matching may fail if the traversal speed between the query and reference sequences differ significantly.


## ðŸ“„ Citation

If you found this repository helpful, please cite the paper below:
<pre>
@ARTICLE{9849680,
  author={Tomiá¹­Äƒ, Mihnea-Alexandru and Zaffar, Mubariz and Ferrarini, Bruno and Milford, Michael J. and McDonald-Maier, Klaus D. and Ehsan, Shoaib},
  journal={IEEE Access}, 
  title={Sequence-Based Filtering for Visual Route-Based Navigation: Analyzing the Benefits, Trade-Offs and Design Choices}, 
  year={2022},
  volume={10},
  number={},
  pages={81974-81987},
  keywords={Filtering;Visualization;Navigation;Convolutional neural networks;Lighting;Image matching;Electronic mail;Sequence-based filtering;visual localization;visual place recognition},
  doi={10.1109/ACCESS.2022.3196389}}
 </pre>

## References for Evaluated VPR Techniques
The sequence-based filtering implementations in this repository build upon the single-frame-based VPR techniques that were evaluated in [VPR-Bench](https://github.com/MubarizZaffar/VPR-Bench) and described in the associated paper:

**Title:** VPR-Bench: An Open-Source Visual Place Recognition Evaluation Framework with Quantifiable Viewpoint and Appearance Change  
**Authors:** M Zaffar, S Garg, M Milford, J Kooij, D Flynn, K McDonald-Maier, S Ehsan  

Published in: International Journal of Computer Vision, 2021 and available [here](https://link.springer.com/article/10.1007/s11263-021-01469-5).

Citations for the original authors can be found in the `ReadMe.txt` file within each technique's folder (e.g. AMOSNet/ReadMe.txt, HOG/ReadMe.txt, etc.). All sequence-based filtering modifications in this repository were added on top of these original implementations, with proper credit given to the original authors for the backbone code.
